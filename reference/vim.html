<!-- Generated by pkgdown: do not edit by hand -->
<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>Nonparametric Variable Importance Estimates and Inference — vim • vimp</title>


<!-- jquery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
<!-- Bootstrap -->

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous" />

<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script>

<!-- bootstrap-toc -->
<link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script>

<!-- Font Awesome icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous" />

<!-- clipboard.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script>

<!-- headroom.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script>

<!-- pkgdown -->
<link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script>




<meta property="og:title" content="Nonparametric Variable Importance Estimates and Inference — vim" />
<meta property="og:description" content="Compute estimates of and confidence intervals for nonparametric risk-based variable importance." />




<!-- mathjax -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script>

<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->



  </head>

  <body data-spy="scroll" data-target="#toc">
    <div class="container template-reference-topic">
      <header>
      <div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">vimp</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">2.1.1</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="../index.html">
    <span class="fas fa fas fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="../articles/introduction-to-vimp.html">Introduction to `vimp`</a>
    </li>
    <li>
      <a href="../articles/precomputed-regressions.html">Using precomputed regression function estimates in `vimp`</a>
    </li>
    <li>
      <a href="../articles/types-of-vims.html">Types of VIMs</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/bdwilliamson/vimp/">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
      
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      

      </header>

<div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>Nonparametric Variable Importance Estimates and Inference</h1>
    <small class="dont-index">Source: <a href='https://github.com/bdwilliamson/vimp/blob/master/R/vim.R'><code>R/vim.R</code></a></small>
    <div class="hidden name"><code>vim.Rd</code></div>
    </div>

    <div class="ref-description">
    <p>Compute estimates of and confidence intervals for nonparametric risk-based variable importance.</p>
    </div>

    <pre class="usage"><span class='fu'>vim</span>(
  <span class='kw'>Y</span>,
  <span class='kw'>X</span>,
  f1 = <span class='kw'>NULL</span>,
  f2 = <span class='kw'>NULL</span>,
  indx = <span class='fl'>1</span>,
  weights = <span class='fu'><a href='https://rdrr.io/r/base/rep.html'>rep</a></span>(<span class='fl'>1</span>, <span class='fu'><a href='https://rdrr.io/r/base/length.html'>length</a></span>(<span class='kw'>Y</span>)),
  type = <span class='st'>"r_squared"</span>,
  run_regression = <span class='fl'>TRUE</span>,
  SL.library = <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(<span class='st'>"SL.glmnet"</span>, <span class='st'>"SL.xgboost"</span>, <span class='st'>"SL.mean"</span>),
  alpha = <span class='fl'>0.05</span>,
  delta = <span class='fl'>0</span>,
  scale = <span class='st'>"identity"</span>,
  na.rm = <span class='fl'>FALSE</span>,
  folds = <span class='kw'>NULL</span>,
  stratified = <span class='fl'>FALSE</span>,
  <span class='kw'>...</span>
)</pre>

    <h2 class="hasAnchor" id="arguments"><a class="anchor" href="#arguments"></a>Arguments</h2>
    <table class="ref-arguments">
    <colgroup><col class="name" /><col class="desc" /></colgroup>
    <tr>
      <th>Y</th>
      <td><p>the outcome.</p></td>
    </tr>
    <tr>
      <th>X</th>
      <td><p>the covariates.</p></td>
    </tr>
    <tr>
      <th>f1</th>
      <td><p>the fitted values from a flexible estimation technique regressing Y on X.</p></td>
    </tr>
    <tr>
      <th>f2</th>
      <td><p>the fitted values from a flexible estimation technique regressing Y on X withholding the columns in <code>indx</code>.</p></td>
    </tr>
    <tr>
      <th>indx</th>
      <td><p>the indices of the covariate(s) to calculate variable importance for; defaults to 1.</p></td>
    </tr>
    <tr>
      <th>weights</th>
      <td><p>weights for the computed influence curve (e.g., inverse probability weights for coarsened-at-random settings)</p></td>
    </tr>
    <tr>
      <th>type</th>
      <td><p>the type of importance to compute; defaults to <code>r_squared</code>, but other supported options are <code>auc</code>, <code>accuracy</code>, and <code>anova</code>.</p></td>
    </tr>
    <tr>
      <th>run_regression</th>
      <td><p>if outcome Y and covariates X are passed to <code>vimp_accuracy</code>, and <code>run_regression</code> is <code>TRUE</code>, then Super Learner will be used; otherwise, variable importance will be computed using the inputted fitted values.</p></td>
    </tr>
    <tr>
      <th>SL.library</th>
      <td><p>a character vector of learners to pass to <code>SuperLearner</code>, if <code>f1</code> and <code>f2</code> are Y and X, respectively. Defaults to <code>SL.glmnet</code>, <code>SL.xgboost</code>, and <code>SL.mean</code>.</p></td>
    </tr>
    <tr>
      <th>alpha</th>
      <td><p>the level to compute the confidence interval at. Defaults to 0.05, corresponding to a 95% confidence interval.</p></td>
    </tr>
    <tr>
      <th>delta</th>
      <td><p>the value of the \(\delta\)-null (i.e., testing if importance &lt; \(\delta\)); defaults to 0.</p></td>
    </tr>
    <tr>
      <th>scale</th>
      <td><p>should CIs be computed on original ("identity") or logit ("logit") scale?</p></td>
    </tr>
    <tr>
      <th>na.rm</th>
      <td><p>should we remove NA's in the outcome and fitted values in computation? (defaults to <code>FALSE</code>)</p></td>
    </tr>
    <tr>
      <th>folds</th>
      <td><p>the folds used for <code>f1</code> and <code>f2</code>; assumed to be 1 for the observations used in <code>f1</code> and 2 for the observations used in <code>f2</code>. If there is only a single fold passed in, then hypothesis testing is not done.</p></td>
    </tr>
    <tr>
      <th>stratified</th>
      <td><p>if run_regression = TRUE, then should the generated folds be stratified based on the outcome (helps to ensure class balance across cross-validation folds)</p></td>
    </tr>
    <tr>
      <th>...</th>
      <td><p>other arguments to the estimation tool, see "See also".</p></td>
    </tr>
    </table>

    <h2 class="hasAnchor" id="value"><a class="anchor" href="#value"></a>Value</h2>

    <p>An object of classes <code>vim</code> and the type of risk-based measure. See Details for more information.</p>
    <h2 class="hasAnchor" id="details"><a class="anchor" href="#details"></a>Details</h2>

    <p>We define the population variable importance measure (VIM) for the group 
of features (or single feature) \(s\) with respect to the predictiveness measure
\(V\) by $$\psi_{0,s} := V(f_0, P_0) - V(f_{0,s}, P_0),$$ where \(f_0\) is 
the population predictiveness maximizing function, \(f_{0,s}\) is the population
predictiveness maximizing function that is only allowed to access the features with
index not in \(s\), and \(P_0\) is the true data-generating distribution. VIM estimates are
obtained by obtaining estimators \(f_n\) and \(f_{n,s}\) of \(f_0\) and \(f_{0,s}\),
respectively; obtaining an estimator \(P_n\) of \(P_0\); and finally, setting \(\psi_{n,s} := V(f_n, P_n) - V(f_{n,s}, P_n)\).</p>
<p>In the interest of transparency, we return most of the calculations
within the <code>vim</code> object. This results in a list containing:</p><ul>
<li><p>call - the call to <code>vim</code></p></li>
<li><p>s - the column(s) to calculate variable importance for</p></li>
<li><p>SL.library - the library of learners passed to <code>SuperLearner</code></p></li>
<li><p>type - the type of risk-based variable importance measured</p></li>
<li><p>full_fit - the fitted values of the chosen method fit to the full data</p></li>
<li><p>red_fit - the fitted values of the chosen method fit to the reduced data</p></li>
<li><p>est - the estimated variable importance</p></li>
<li><p>naive - the naive estimator of variable importance</p></li>
<li><p>update - the influence curve-based update</p></li>
<li><p>se - the standard error for the estimated variable importance</p></li>
<li><p>ci - the \((1-\alpha) \times 100\)% confidence interval for the variable importance estimate</p></li>
<li><p>test - a decision to either reject (TRUE) or not reject (FALSE) the null hypothesis, based on a conservative test</p></li>
<li><p>pval - a conservative p-value based on the same conservative test as <code>test</code></p></li>
<li><p>full_mod - the object returned by the estimation procedure for the full data regression (if applicable)</p></li>
<li><p>red_mod - the object returned by the estimation procedure for the reduced data regression (if applicable)</p></li>
<li><p>alpha - the level, for confidence interval calculation</p></li>
<li><p>folds - the folds used for hypothesis testing</p></li>
<li><p>y - the outcome</p></li>
<li><p>weights - the weights</p></li>
<li><p>mat- a tibble with the estimate, SE, CI, hypothesis testing decision, and p-value</p></li>
</ul>

    <h2 class="hasAnchor" id="see-also"><a class="anchor" href="#see-also"></a>See also</h2>

    <div class='dont-index'><p><code><a href='https://rdrr.io/pkg/SuperLearner/man/SuperLearner.html'>SuperLearner</a></code> for specific usage of the <code>SuperLearner</code> function and package.</p></div>

    <h2 class="hasAnchor" id="examples"><a class="anchor" href="#examples"></a>Examples</h2>
    <pre class="examples"><div class='input'><span class='fu'><a href='https://rdrr.io/r/base/library.html'>library</a></span>(<span class='kw'><a href='https://github.com/ecpolley/SuperLearner'>SuperLearner</a></span>)
<span class='fu'><a href='https://rdrr.io/r/base/library.html'>library</a></span>(<span class='kw'><a href='https://github.com/imbs-hl/ranger'>ranger</a></span>)
<span class='co'>## generate the data</span>
<span class='co'>## generate X</span>
<span class='kw'>p</span> <span class='op'>&lt;-</span> <span class='fl'>2</span>
<span class='kw'>n</span> <span class='op'>&lt;-</span> <span class='fl'>100</span>
<span class='kw'>x</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/data.frame.html'>data.frame</a></span>(<span class='fu'><a href='https://rdrr.io/r/base/lapply.html'>replicate</a></span>(<span class='kw'>p</span>, <span class='kw'>stats</span>::<span class='fu'><a href='https://rdrr.io/r/stats/Uniform.html'>runif</a></span>(<span class='kw'>n</span>, <span class='op'>-</span><span class='fl'>1</span>, <span class='fl'>1</span>)))

<span class='co'>## apply the function to the x's</span>
<span class='kw'>f</span> <span class='op'>&lt;-</span> <span class='fu'>function</span>(<span class='kw'>x</span>) <span class='fl'>0.5</span> <span class='op'>+</span> <span class='fl'>0.3</span><span class='op'>*</span><span class='kw'>x</span>[<span class='fl'>1</span>] <span class='op'>+</span> <span class='fl'>0.2</span><span class='op'>*</span><span class='kw'>x</span>[<span class='fl'>2</span>]
<span class='kw'>smooth</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/apply.html'>apply</a></span>(<span class='kw'>x</span>, <span class='fl'>1</span>, <span class='fu'>function</span>(<span class='kw'>z</span>) <span class='fu'>f</span>(<span class='kw'>z</span>))

<span class='co'>## generate Y ~ Normal (smooth, 1)</span>
<span class='kw'>y</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/matrix.html'>matrix</a></span>(<span class='fu'><a href='https://rdrr.io/r/stats/Binomial.html'>rbinom</a></span>(<span class='kw'>n</span>, size = <span class='fl'>1</span>, prob = <span class='kw'>smooth</span>))

<span class='co'>## set up a library for SuperLearner</span>
<span class='kw'>learners</span> <span class='op'>&lt;-</span> <span class='st'>"SL.ranger"</span>

<span class='co'>## using Y and X; use class-balanced folds</span>
<span class='kw'>folds_1</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/sample.html'>sample</a></span>(<span class='fu'><a href='https://rdrr.io/r/base/rep.html'>rep</a></span>(<span class='fu'><a href='https://rdrr.io/r/base/seq.html'>seq_len</a></span>(<span class='fl'>2</span>), length = <span class='fu'><a href='https://rdrr.io/r/base/sum.html'>sum</a></span>(<span class='kw'>y</span> <span class='op'>==</span> <span class='fl'>1</span>)))
<span class='kw'>folds_0</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/sample.html'>sample</a></span>(<span class='fu'><a href='https://rdrr.io/r/base/rep.html'>rep</a></span>(<span class='fu'><a href='https://rdrr.io/r/base/seq.html'>seq_len</a></span>(<span class='fl'>2</span>), length = <span class='fu'><a href='https://rdrr.io/r/base/sum.html'>sum</a></span>(<span class='kw'>y</span> <span class='op'>==</span> <span class='fl'>0</span>)))
<span class='kw'>folds</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/vector.html'>vector</a></span>(<span class='st'>"numeric"</span>, <span class='fu'><a href='https://rdrr.io/r/base/length.html'>length</a></span>(<span class='kw'>y</span>))
<span class='kw'>folds</span>[<span class='kw'>y</span> <span class='op'>==</span> <span class='fl'>1</span>] <span class='op'>&lt;-</span> <span class='kw'>folds_1</span>
<span class='kw'>folds</span>[<span class='kw'>y</span> <span class='op'>==</span> <span class='fl'>0</span>] <span class='op'>&lt;-</span> <span class='kw'>folds_0</span>
<span class='kw'>est</span> <span class='op'>&lt;-</span> <span class='fu'>vim</span>(<span class='kw'>y</span>, <span class='kw'>x</span>, indx = <span class='fl'>2</span>, type = <span class='st'>"r_squared"</span>,
           alpha = <span class='fl'>0.05</span>, run_regression = <span class='fl'>TRUE</span>,
           SL.library = <span class='kw'>learners</span>, cvControl = <span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span>(V = <span class='fl'>2</span>),
           folds = <span class='kw'>folds</span>)
</div><div class='output co'>#&gt; Error in data.frame(..., check.names = FALSE) : 
#&gt;   arguments imply differing number of rows: 26, 24</div><div class='output co'>#&gt; <span class='warning'>Warning: Error in algorithm SL.ranger </span>
#&gt; <span class='warning'>  The Algorithm will be removed from the Super Learner (i.e. given weight 0) </span></div><div class='output co'>#&gt; Error in data.frame(..., check.names = FALSE) : 
#&gt;   arguments imply differing number of rows: 27, 25</div><div class='output co'>#&gt; <span class='warning'>Warning: Error in algorithm SL.ranger </span>
#&gt; <span class='warning'>  The Algorithm will be removed from the Super Learner (i.e. given weight 0) </span></div><div class='output co'>#&gt; <span class='error'>Error in (function (Y, X, newX = NULL, family = gaussian(), SL.library,     method = "method.NNLS", id = NULL, verbose = FALSE, control = list(),     cvControl = list(), obsWeights = NULL, env = parent.frame()) {    time_start = proc.time()    if (is.character(method)) {        if (exists(method, mode = "list")) {            method &lt;- get(method, mode = "list")        }        else if (exists(method, mode = "function")) {            method &lt;- get(method, mode = "function")()        }    }    else if (is.function(method)) {        method &lt;- method()    }    if (!is.list(method)) {        stop("method is not in the appropriate format. Check out help('method.template')")    }    if (!is.null(method$require)) {        sapply(method$require, function(x) require(force(x),             character.only = TRUE))    }    control &lt;- do.call("SuperLearner.control", control)    cvControl &lt;- do.call("SuperLearner.CV.control", cvControl)    library &lt;- .createLibrary(SL.library)    .check.SL.library(library = c(unique(library$library$predAlgorithm),         library$screenAlgorithm))    call &lt;- match.call(expand.dots = TRUE)    if (!inherits(X, "data.frame"))         message("X is not a data frame. Check the algorithms in SL.library to make sure they are compatible with non data.frame inputs")    varNames &lt;- colnames(X)    N &lt;- dim(X)[1L]    p &lt;- dim(X)[2L]    k &lt;- nrow(library$library)    kScreen &lt;- length(library$screenAlgorithm)    Z &lt;- matrix(NA, N, k)    libraryNames &lt;- paste(library$library$predAlgorithm, library$screenAlgorithm[library$library$rowScreen],         sep = "_")    if (p &lt; 2 &amp; !identical(library$screenAlgorithm, "All")) {        warning("Screening algorithms specified in combination with single-column X.")    }    fitLibEnv &lt;- new.env()    assign("fitLibrary", vector("list", length = k), envir = fitLibEnv)    assign("libraryNames", libraryNames, envir = fitLibEnv)    evalq(names(fitLibrary) &lt;- libraryNames, envir = fitLibEnv)    errorsInCVLibrary &lt;- rep(0, k)    errorsInLibrary &lt;- rep(0, k)    if (is.null(newX)) {        newX &lt;- X    }    if (!identical(colnames(X), colnames(newX))) {        stop("The variable names and order in newX must be identical to the variable names and order in X")    }    if (sum(is.na(X)) &gt; 0 | sum(is.na(newX)) &gt; 0 | sum(is.na(Y)) &gt;         0) {        stop("missing data is currently not supported. Check Y, X, and newX for missing values")    }    if (!is.numeric(Y)) {        stop("the outcome Y must be a numeric vector")    }    if (is.character(family))         family &lt;- get(family, mode = "function", envir = parent.frame())    if (is.function(family))         family &lt;- family()    if (is.null(family$family)) {        print(family)        stop("'family' not recognized")    }    if (family$family != "binomial" &amp; isTRUE("cvAUC" %in% method$require)) {        stop("'method.AUC' is designed for the 'binomial' family only")    }    validRows &lt;- CVFolds(N = N, id = id, Y = Y, cvControl = cvControl)    if (is.null(id)) {        id &lt;- seq(N)    }    if (!identical(length(id), N)) {        stop("id vector must have the same dimension as Y")    }    if (is.null(obsWeights)) {        obsWeights &lt;- rep(1, N)    }    if (!identical(length(obsWeights), N)) {        stop("obsWeights vector must have the same dimension as Y")    }    .crossValFUN &lt;- function(valid, Y, dataX, id, obsWeights,         library, kScreen, k, p, libraryNames, saveCVFitLibrary) {        tempLearn &lt;- dataX[-valid, , drop = FALSE]        tempOutcome &lt;- Y[-valid]        tempValid &lt;- dataX[valid, , drop = FALSE]        tempWhichScreen &lt;- matrix(NA, nrow = kScreen, ncol = p)        tempId &lt;- id[-valid]        tempObsWeights &lt;- obsWeights[-valid]        for (s in seq(kScreen)) {            screen_fn = get(library$screenAlgorithm[s], envir = env)            testScreen &lt;- try(do.call(screen_fn, list(Y = tempOutcome,                 X = tempLearn, family = family, id = tempId,                 obsWeights = tempObsWeights)))            if (inherits(testScreen, "try-error")) {                warning(paste("replacing failed screening algorithm,",                   library$screenAlgorithm[s], ", with All()",                   "\n "))                tempWhichScreen[s, ] &lt;- TRUE            }            else {                tempWhichScreen[s, ] &lt;- testScreen            }            if (verbose) {                message(paste("Number of covariates in ", library$screenAlgorithm[s],                   " is: ", sum(tempWhichScreen[s, ]), sep = ""))            }        }        out &lt;- matrix(NA, nrow = nrow(tempValid), ncol = k)        if (saveCVFitLibrary) {            model_out &lt;- vector(mode = "list", length = k)        }        else {            model_out &lt;- NULL        }        for (s in seq(k)) {            pred_fn = get(library$library$predAlgorithm[s], envir = env)            testAlg &lt;- try(do.call(pred_fn, list(Y = tempOutcome,                 X = subset(tempLearn, select = tempWhichScreen[library$library$rowScreen[s],                   ], drop = FALSE), newX = subset(tempValid,                   select = tempWhichScreen[library$library$rowScreen[s],                     ], drop = FALSE), family = family, id = tempId,                 obsWeights = tempObsWeights)))            if (inherits(testAlg, "try-error")) {                warning(paste("Error in algorithm", library$library$predAlgorithm[s],                   "\n  The Algorithm will be removed from the Super Learner (i.e. given weight 0) \n"))            }            else {                out[, s] &lt;- testAlg$pred                if (saveCVFitLibrary) {                  model_out[[s]] &lt;- testAlg$fit                }            }            if (verbose)                 message(paste("CV", libraryNames[s]))        }        if (saveCVFitLibrary) {            names(model_out) &lt;- libraryNames        }        invisible(list(out = out, model_out = model_out))    }    time_train_start = proc.time()    crossValFUN_out &lt;- lapply(validRows, FUN = .crossValFUN,         Y = Y, dataX = X, id = id, obsWeights = obsWeights, library = library,         kScreen = kScreen, k = k, p = p, libraryNames = libraryNames,         saveCVFitLibrary = control$saveCVFitLibrary)    Z[unlist(validRows, use.names = FALSE), ] &lt;- do.call("rbind",         lapply(crossValFUN_out, "[[", "out"))    if (control$saveCVFitLibrary) {        cvFitLibrary &lt;- lapply(crossValFUN_out, "[[", "model_out")    }    else {        cvFitLibrary &lt;- NULL    }    errorsInCVLibrary &lt;- apply(Z, 2, function(x) anyNA(x))    if (sum(errorsInCVLibrary) &gt; 0) {        Z[, as.logical(errorsInCVLibrary)] &lt;- 0    }    if (all(Z == 0)) {        stop("All algorithms dropped from library")    }    getCoef &lt;- method$computeCoef(Z = Z, Y = Y, libraryNames = libraryNames,         obsWeights = obsWeights, control = control, verbose = verbose,         errorsInLibrary = errorsInCVLibrary)    coef &lt;- getCoef$coef    names(coef) &lt;- libraryNames    time_train = proc.time() - time_train_start    if (!("optimizer" %in% names(getCoef))) {        getCoef["optimizer"] &lt;- NA    }    m &lt;- dim(newX)[1L]    predY &lt;- matrix(NA, nrow = m, ncol = k)    .screenFun &lt;- function(fun, list) {        screen_fn = get(fun, envir = env)        testScreen &lt;- try(do.call(screen_fn, list))        if (inherits(testScreen, "try-error")) {            warning(paste("replacing failed screening algorithm,",                 fun, ", with All() in full data", "\n "))            out &lt;- rep(TRUE, ncol(list$X))        }        else {            out &lt;- testScreen        }        return(out)    }    time_predict_start = proc.time()    whichScreen &lt;- sapply(library$screenAlgorithm, FUN = .screenFun,         list = list(Y = Y, X = X, family = family, id = id, obsWeights = obsWeights),         simplify = FALSE)    whichScreen &lt;- do.call(rbind, whichScreen)    .predFun &lt;- function(index, lib, Y, dataX, newX, whichScreen,         family, id, obsWeights, verbose, control, libraryNames) {        pred_fn = get(lib$predAlgorithm[index], envir = env)        testAlg &lt;- try(do.call(pred_fn, list(Y = Y, X = subset(dataX,             select = whichScreen[lib$rowScreen[index], ], drop = FALSE),             newX = subset(newX, select = whichScreen[lib$rowScreen[index],                 ], drop = FALSE), family = family, id = id, obsWeights = obsWeights)))        if (inherits(testAlg, "try-error")) {            warning(paste("Error in algorithm", lib$predAlgorithm[index],                 " on full data", "\n  The Algorithm will be removed from the Super Learner (i.e. given weight 0) \n"))            out &lt;- rep.int(NA, times = nrow(newX))        }        else {            out &lt;- testAlg$pred            if (control$saveFitLibrary) {                eval(bquote(fitLibrary[[.(index)]] &lt;- .(testAlg$fit)),                   envir = fitLibEnv)            }        }        if (verbose) {            message(paste("full", libraryNames[index]))        }        invisible(out)    }    predY &lt;- do.call("cbind", lapply(seq(k), FUN = .predFun,         lib = library$library, Y = Y, dataX = X, newX = newX,         whichScreen = whichScreen, family = family, id = id,         obsWeights = obsWeights, verbose = verbose, control = control,         libraryNames = libraryNames))    errorsInLibrary &lt;- apply(predY, 2, function(algorithm) anyNA(algorithm))    if (sum(errorsInLibrary) &gt; 0) {        if (sum(coef[as.logical(errorsInLibrary)]) &gt; 0) {            warning(paste0("Re-running estimation of coefficients removing failed algorithm(s)\n",                 "Original coefficients are: \n", paste(coef,                   collapse = ", "), "\n"))            Z[, as.logical(errorsInLibrary)] &lt;- 0            if (all(Z == 0)) {                stop("All algorithms dropped from library")            }            getCoef &lt;- method$computeCoef(Z = Z, Y = Y, libraryNames = libraryNames,                 obsWeights = obsWeights, control = control, verbose = verbose,                 errorsInLibrary = errorsInLibrary)            coef &lt;- getCoef$coef            names(coef) &lt;- libraryNames        }        else {            warning("Coefficients already 0 for all failed algorithm(s)")        }    }    getPred &lt;- method$computePred(predY = predY, coef = coef,         control = control)    time_predict = proc.time() - time_predict_start    colnames(predY) &lt;- libraryNames    if (sum(errorsInCVLibrary) &gt; 0) {        getCoef$cvRisk[as.logical(errorsInCVLibrary)] &lt;- NA    }    time_end = proc.time()    times = list(everything = time_end - time_start, train = time_train,         predict = time_predict)    out &lt;- list(call = call, libraryNames = libraryNames, SL.library = library,         SL.predict = getPred, coef = coef, library.predict = predY,         Z = Z, cvRisk = getCoef$cvRisk, family = family, fitLibrary = get("fitLibrary",             envir = fitLibEnv), cvFitLibrary = cvFitLibrary,         varNames = varNames, validRows = validRows, method = method,         whichScreen = whichScreen, control = control, cvControl = cvControl,         errorsInCVLibrary = errorsInCVLibrary, errorsInLibrary = errorsInLibrary,         metaOptimizer = getCoef$optimizer, env = env, times = times)    class(out) &lt;- c("SuperLearner")    return(out)})(cvControl = list(V = 2), family = structure(list(family = "gaussian",     link = "identity", linkfun = function (mu)     mu, linkinv = function (eta)     eta, variance = function (mu)     rep.int(1, length(mu)), dev.resids = function (y, mu, wt)     wt * ((y - mu)^2), aic = function (y, n, mu, wt, dev)     {        nobs &lt;- length(y)        nobs * (log(dev/nobs * 2 * pi) + 1) + 2 - sum(log(wt))    }, mu.eta = function (eta)     rep.int(1, length(eta)), initialize = expression({        n &lt;- rep.int(1, nobs)        if (is.null(etastart) &amp;&amp; is.null(start) &amp;&amp; is.null(mustart) &amp;&amp;             ((family$link == "inverse" &amp;&amp; any(y == 0)) || (family$link ==                 "log" &amp;&amp; any(y &lt;= 0))))             stop("cannot find valid starting values: please specify some")        mustart &lt;- y    }), validmu = function (mu)     TRUE, valideta = function (eta)     TRUE), class = "family"), Y = structure(c(0.716033333333334, 0.8915, 0.791433333333334, 0.3265, 0.233966666666667, 0.824800000000001, 0.630566666666666, 0.0326333333333333, 0.8264, 0.729266666666667, 0.274666666666667, 0.782066666666667, 0.474233333333333, 0.2663, 0.713166666666667, 0.303466666666667, 0.6997, 0.312866666666667, 0.4274, 0.511366666666667, 0.6662, 0.5423, 0.573966666666666, 0.347166666666667, 0.259433333333333, 0.714833333333333, 0.239533333333333, 0.677066666666667, 0.210166666666667, 0.0943333333333334, 0.696333333333333, 0.826433333333333, 0.635, 0.219133333333333, 0.594533333333333, 0.234366666666667, 0.0876333333333333, 0.280566666666667, 0.3992, 0.1142, 0.2058, 0.716066666666667, 0.0433333333333333, 0.0415666666666666, 0.0445666666666667, 0.0836, 0.8141, 0.0663666666666667, 0.7699, 0.6073, 0.8933), .Dim = c(51L, 1L)), X = structure(list(X1 = c(-0.753771381918341, -0.143795292358845, 0.285397629719228, -0.598208559677005, 0.152677124366164, 0.868483573198318, -0.59913653600961, -0.386898460797966, 0.669352719094604, 0.894915781915188, -0.539103284012526, 0.894362262450159, -0.305378235410899, -0.757027229294181, -0.376907113939524, 0.168692866805941, -0.455501619726419, -0.358561683446169, -0.114100332371891, 0.814544485881925, 0.482119514606893, 0.620705139823258, 0.319245150778443, -0.0643384926952422, 0.865729700773954, -0.0245725363492966, 0.479926395229995, -0.598868171684444, 0.0541091421619058, 0.705140637699515, -0.679088393226266, -0.110585407819599, -0.594418883323669, 0.954369420185685, -0.768858699128032, -0.612607419025153, 0.19230820890516, 0.623889425769448, 0.208979279734194, -0.532531827688217, 0.240859299432486, -0.14225233765319, -0.946452054195106, -0.518148417584598, -0.507158214226365, -0.683654933236539, 0.962758276611567, -0.480572562664747, -0.846726555377245)), row.names = c(2L, 3L, 5L, 6L, 13L, 20L, 21L, 22L, 24L, 28L, 29L, 30L, 32L, 35L, 36L, 38L, 39L, 40L, 43L, 46L, 47L, 48L, 51L, 53L, 56L, 58L, 66L, 69L, 72L, 73L, 74L, 76L, 77L, 78L, 79L, 80L, 81L, 82L, 83L, 85L, 86L, 87L, 88L, 89L, 90L, 92L, 96L, 97L, 100L), class = "data.frame"), SL.library = "SL.ranger"): All algorithms dropped from library</span></div><div class='input'>
<span class='co'>## using pre-computed fitted values</span>
<span class='kw'>full</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/SuperLearner/man/SuperLearner.html'>SuperLearner</a></span>(Y = <span class='kw'>y</span>[<span class='kw'>folds</span> <span class='op'>==</span> <span class='fl'>1</span>], X = <span class='kw'>x</span>[<span class='kw'>folds</span> <span class='op'>==</span> <span class='fl'>1</span>, ],
SL.library = <span class='kw'>learners</span>, cvControl = <span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span>(V = <span class='fl'>2</span>))
<span class='kw'>full.fit</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/predict.html'>predict</a></span>(<span class='kw'>full</span>)<span class='op'>$</span><span class='kw'>pred</span>
<span class='kw'>reduced</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/SuperLearner/man/SuperLearner.html'>SuperLearner</a></span>(Y = <span class='kw'>y</span>[<span class='kw'>folds</span> <span class='op'>==</span> <span class='fl'>2</span>], X = <span class='kw'>x</span>[<span class='kw'>folds</span> <span class='op'>==</span> <span class='fl'>2</span>, <span class='op'>-</span><span class='fl'>2</span>, drop = <span class='fl'>FALSE</span>],
SL.library = <span class='kw'>learners</span>, cvControl = <span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span>(V = <span class='fl'>2</span>))
<span class='kw'>red.fit</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/predict.html'>predict</a></span>(<span class='kw'>reduced</span>)<span class='op'>$</span><span class='kw'>pred</span>

<span class='kw'>est</span> <span class='op'>&lt;-</span> <span class='fu'>vim</span>(Y = <span class='kw'>y</span>, f1 = <span class='kw'>full.fit</span>, f2 = <span class='kw'>red.fit</span>,
            indx = <span class='fl'>2</span>, run_regression = <span class='fl'>FALSE</span>, alpha = <span class='fl'>0.05</span>, folds = <span class='kw'>folds</span>,
            type = <span class='st'>"accuracy"</span>)

</div></pre>
  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">
    <nav id="toc" data-toggle="toc" class="sticky-top">
      <h2 data-toc-skip>Contents</h2>
    </nav>
  </div>
</div>


      <footer>
      <div class="copyright">
  <p>Developed by Brian D. Williamson, Noah Simon, Marco Carone.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.6.1.9000.</p>
</div>

      </footer>
   </div>

  


  </body>
</html>


