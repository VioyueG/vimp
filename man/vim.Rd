% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/vim.R
\name{vim}
\alias{vim}
\title{Nonparametric Variable Importance Estimates}
\usage{
vim(f1, f2, data = NULL, y = data[, 1], n = length(y), indx = 1,
  standardized = TRUE, two_phase = FALSE, tmle = FALSE, na.rm = FALSE,
  return_naive = FALSE, alpha = 0.05, SL.library = NULL,
  tol = .Machine$double.eps, max_iter = 500, ...)
}
\arguments{
\item{f1}{either: (1) the regression function to estimate for the full fit,
in the form \code{y ~ x} if using Super Learner; or (2) the fitted values from a flexible estimation technique.}

\item{f2}{either: (1) the regression function to estimate for the reduced fit,
in the form \code{y ~ x} or \code{fit ~ x} if using Super Learner without or with the sequential regression (recommended), respectively; or (2) the fitted values from a flexible estimation technique.}

\item{data}{the dataset. Must be \eqn{n x (p+1)}, where the first
column is \eqn{Y}.}

\item{y}{the outcome; by default is the first column in \code{data}.}

\item{n}{the sample size.}

\item{indx}{the indices of the covariate(s) to calculate variable importance for,
defaults to 1.}

\item{standardized}{should we estimate the standardized parameter? (defaults to \code{TRUE})}

\item{two_phase}{did the data come from a two-phase sample? (defaults to \code{FALSE})}

\item{tmle}{should we use the one-step-based estimator (\code{FALSE}) or the TMLE-based estimator (\code{TRUE}) (defaults to \code{FALSE}).}

\item{na.rm}{should we remove NA's in the outcome and fitted values in computation? (defaults to \code{FALSE})}

\item{return_naive}{should we return the naive estimator of importance as well? (defaults to \code{FALSE})}

\item{alpha}{the level to compute the confidence interval at.
Defaults to 0.05, corresponding to a 95\% confidence interval.}

\item{SL.library}{a character vector of learners to pass to \code{SuperLearner}, if \code{f1} and \code{f2} are formulas.}

\item{tol}{numerical error tolerance (only used if \code{tmle = TRUE}).}

\item{max_iter}{maximum number of TMLE iterations (only used if \code{tmle = TRUE}).}

\item{...}{other arguments to the estimation tool, see "See also".}
}
\value{
An object of class \code{vim}. See Details for more information.
}
\description{
Compute estimates and confidence intervals for the
nonparametric variable importance parameter of interest.
}
\details{
See the paper by Williamson, Gilbert, Simon, and Carone for more
details on the mathematics behind this function, and the validity
of the confidence intervals.
In the interest of transparency, we return most of the calculations
within the \code{vim} object. This results in a list containing:
\itemize{
 \item{call}{ - the call to \code{vim}}
 \item{full.f}{ - either the formula for the full regression or the fitted values for the full regression, based on the \code{call}}
 \item{red.f}{ - either the formula for the reduced regression or the fitted values for the reduced regression, based on the \code{call}}
 \item{data}{ - the data used by the function}
 \item{s}{ - the column(s) to calculate variable importance for}
 \item{SL.library}{ - the library of learners passed to \code{SuperLearner}}
 \item{full.fit}{ - the fitted values of the chosen method fit to the full data}
 \item{red.fit}{ - the fitted values of the chosen method fit to the reduced data}
 \item{est}{ - the estimated variable importance}
 \item{se}{ - the standard error for the estimated variable importance}
 \item{ci}{ - the \eqn{(1-\alpha) x 100}\% confidence interval for the variable importance estimate}
 \item{full.mod}{ - the object returned by the estimation procedure for the full data regression (if applicable)}
 \item{red.mod}{ - the object returned by the estimation procedure for the reduced data regression (if applicable)}
 \item{alpha}{ - the level, for confidence interval calculation}
}
}
\examples{
\dontrun{
require(SuperLearner)
## generate the data
## generate X
p <- 2
n <- 100
x <- replicate(p, stats::runif(n, -5, 5))

## apply the function to the x's
smooth <- (x[,1]/5)^2*(x[,1]+7)/5 + (x[,2]/3)^2

## generate Y ~ Normal (smooth, 1)
y <- smooth + stats::rnorm(n, 0, 1)

testdat <- as.data.frame(cbind(y, x))

## set up a library for SuperLearner
learners <- "SL.gam"

## using class "formula"
est <- vim(y ~ x, fit ~ x, data = testdat, y = testdat[, 1],
           n = length(y), indx = 2, standardized = TRUE, alpha = 0.05,
           SL.library = learners, cvControl = list(V = 10))

## using pre-computed fitted values
full <- SuperLearner(Y = testdat$y, X = testdat[, 2:3],
SL.library = learners, cvControl = list(V = 10))
full.fit <- predict(full)$pred
reduced <- SuperLearner(Y = full.fit, X = testdat[, 3],
SL.library = learners, cvControl = list(V = 10))
red.fit <- predict(reduced)$pred

est <- vim(full.fit, reduced.fit, y = testdat$y, indx = 2,
standardized = TRUE, alpha = 0.05)
}

}
\seealso{
\code{\link{SuperLearner}} for specific usage of the \code{SuperLearner} function and package.
}
