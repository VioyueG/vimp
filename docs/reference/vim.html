<!-- Generated by pkgdown: do not edit by hand -->
<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>Nonparametric Variable Importance Estimates — vim • vimp</title>

<!-- jquery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
<!-- Bootstrap -->

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous" />
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script>

<!-- bootstrap-toc -->
<link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script>

<!-- Font Awesome icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous" />

<!-- clipboard.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script>

<!-- headroom.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script>

<!-- pkgdown -->
<link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script>



<meta property="og:title" content="Nonparametric Variable Importance Estimates — vim" />

<meta property="og:description" content="Compute estimates of and confidence intervals for nonparametric risk-based variable importance." />





<!-- mathjax -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script>

<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->



  </head>

  <body data-spy="scroll" data-target="#toc">
    <div class="container template-reference-topic">
      <header>
      <div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">vimp</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">2.0.1</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="../index.html">
    <span class="fas fa fas fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="../articles/introduction_to_vimp.html">Introduction to vimp</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
      </ul>
      
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
      
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      

      </header>

<div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>Nonparametric Variable Importance Estimates</h1>
    
    <div class="hidden name"><code>vim.Rd</code></div>
    </div>

    <div class="ref-description">
    
    <p>Compute estimates of and confidence intervals for nonparametric risk-based variable importance.</p>
    
    </div>

    <pre class="usage"><span class='fu'>vim</span>(
  <span class='no'>Y</span>,
  <span class='no'>X</span>,
  <span class='kw'>f1</span> <span class='kw'>=</span> <span class='kw'>NULL</span>,
  <span class='kw'>f2</span> <span class='kw'>=</span> <span class='kw'>NULL</span>,
  <span class='kw'>indx</span> <span class='kw'>=</span> <span class='fl'>1</span>,
  <span class='kw'>weights</span> <span class='kw'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/rep.html'>rep</a></span>(<span class='fl'>1</span>, <span class='fu'><a href='https://rdrr.io/r/base/length.html'>length</a></span>(<span class='no'>Y</span>)),
  <span class='kw'>type</span> <span class='kw'>=</span> <span class='st'>"r_squared"</span>,
  <span class='kw'>run_regression</span> <span class='kw'>=</span> <span class='fl'>TRUE</span>,
  <span class='kw'>SL.library</span> <span class='kw'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(<span class='st'>"SL.glmnet"</span>, <span class='st'>"SL.xgboost"</span>, <span class='st'>"SL.mean"</span>),
  <span class='kw'>alpha</span> <span class='kw'>=</span> <span class='fl'>0.05</span>,
  <span class='kw'>delta</span> <span class='kw'>=</span> <span class='fl'>0</span>,
  <span class='kw'>scale</span> <span class='kw'>=</span> <span class='st'>"identity"</span>,
  <span class='kw'>na.rm</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>,
  <span class='kw'>folds</span> <span class='kw'>=</span> <span class='kw'>NULL</span>,
  <span class='kw'>stratified</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>,
  <span class='no'>...</span>
)</pre>
    
    <h2 class="hasAnchor" id="arguments"><a class="anchor" href="#arguments"></a>Arguments</h2>
    <table class="ref-arguments">
    <colgroup><col class="name" /><col class="desc" /></colgroup>
    <tr>
      <th>Y</th>
      <td><p>the outcome.</p></td>
    </tr>
    <tr>
      <th>X</th>
      <td><p>the covariates.</p></td>
    </tr>
    <tr>
      <th>f1</th>
      <td><p>the fitted values from a flexible estimation technique regressing Y on X.</p></td>
    </tr>
    <tr>
      <th>f2</th>
      <td><p>the fitted values from a flexible estimation technique regressing Y on X withholding the columns in <code>indx</code>.</p></td>
    </tr>
    <tr>
      <th>indx</th>
      <td><p>the indices of the covariate(s) to calculate variable importance for; defaults to 1.</p></td>
    </tr>
    <tr>
      <th>weights</th>
      <td><p>weights for the computed influence curve (e.g., inverse probability weights for coarsened-at-random settings)</p></td>
    </tr>
    <tr>
      <th>type</th>
      <td><p>the type of importance to compute; defaults to <code>r_squared</code>, but other supported options are <code>auc</code>, <code>accuracy</code>, and <code>anova</code>.</p></td>
    </tr>
    <tr>
      <th>run_regression</th>
      <td><p>if outcome Y and covariates X are passed to <code>vimp_accuracy</code>, and <code>run_regression</code> is <code>TRUE</code>, then Super Learner will be used; otherwise, variable importance will be computed using the inputted fitted values.</p></td>
    </tr>
    <tr>
      <th>SL.library</th>
      <td><p>a character vector of learners to pass to <code>SuperLearner</code>, if <code>f1</code> and <code>f2</code> are Y and X, respectively. Defaults to <code>SL.glmnet</code>, <code>SL.xgboost</code>, and <code>SL.mean</code>.</p></td>
    </tr>
    <tr>
      <th>alpha</th>
      <td><p>the level to compute the confidence interval at. Defaults to 0.05, corresponding to a 95% confidence interval.</p></td>
    </tr>
    <tr>
      <th>delta</th>
      <td><p>the value of the \(\delta\)-null (i.e., testing if importance &lt; \(\delta\)); defaults to 0.</p></td>
    </tr>
    <tr>
      <th>scale</th>
      <td><p>should CIs be computed on original ("identity") or logit ("logit") scale?</p></td>
    </tr>
    <tr>
      <th>na.rm</th>
      <td><p>should we remove NA's in the outcome and fitted values in computation? (defaults to <code>FALSE</code>)</p></td>
    </tr>
    <tr>
      <th>folds</th>
      <td><p>the folds used for <code>f1</code> and <code>f2</code>; assumed to be 1 for the observations used in <code>f1</code> and 2 for the observations used in <code>f2</code>. If there is only a single fold passed in, then hypothesis testing is not done.</p></td>
    </tr>
    <tr>
      <th>stratified</th>
      <td><p>if run_regression = TRUE, then should the generated folds be stratified based on the outcome (helps to ensure class balance across cross-validation folds)</p></td>
    </tr>
    <tr>
      <th>...</th>
      <td><p>other arguments to the estimation tool, see "See also".</p></td>
    </tr>
    </table>
    
    <h2 class="hasAnchor" id="value"><a class="anchor" href="#value"></a>Value</h2>

    <p>An object of classes <code>vim</code> and the type of risk-based measure. See Details for more information.</p>
    
    <h2 class="hasAnchor" id="details"><a class="anchor" href="#details"></a>Details</h2>

    <p>In the interest of transparency, we return most of the calculations
within the <code>vim</code> object. This results in a list containing:</p><ul>
<li><p>call - the call to <code>vim</code></p></li>
<li><p>s - the column(s) to calculate variable importance for</p></li>
<li><p>SL.library - the library of learners passed to <code>SuperLearner</code></p></li>
<li><p>type - the type of risk-based variable importance measured</p></li>
<li><p>full_fit - the fitted values of the chosen method fit to the full data</p></li>
<li><p>red_fit - the fitted values of the chosen method fit to the reduced data</p></li>
<li><p>est - the estimated variable importance</p></li>
<li><p>naive - the naive estimator of variable importance</p></li>
<li><p>update - the influence curve-based update</p></li>
<li><p>se - the standard error for the estimated variable importance</p></li>
<li><p>ci - the \((1-\alpha) \times 100\)% confidence interval for the variable importance estimate</p></li>
<li><p>test - a decision to either reject (TRUE) or not reject (FALSE) the null hypothesis, based on a conservative test</p></li>
<li><p>pval - a conservative p-value based on the same conservative test as <code>test</code></p></li>
<li><p>full_mod - the object returned by the estimation procedure for the full data regression (if applicable)</p></li>
<li><p>red_mod - the object returned by the estimation procedure for the reduced data regression (if applicable)</p></li>
<li><p>alpha - the level, for confidence interval calculation</p></li>
<li><p>folds - the folds used for hypothesis testing</p></li>
<li><p>y - the outcome</p></li>
<li><p>weights - the weights</p></li>
<li><p>mat- a tibble with the estimate, SE, CI, hypothesis testing decision, and p-value</p></li>
</ul>

    
    <h2 class="hasAnchor" id="see-also"><a class="anchor" href="#see-also"></a>See also</h2>

    <div class='dont-index'><p><code><a href='https://rdrr.io/pkg/SuperLearner/man/SuperLearner.html'>SuperLearner</a></code> for specific usage of the <code>SuperLearner</code> function and package.</p></div>
    

    <h2 class="hasAnchor" id="examples"><a class="anchor" href="#examples"></a>Examples</h2>
    <pre class="examples"><div class='input'><span class='fu'><a href='https://rdrr.io/r/base/library.html'>library</a></span>(<span class='no'>SuperLearner</span>)
<span class='fu'><a href='https://rdrr.io/r/base/library.html'>library</a></span>(<span class='no'>ranger</span>)
<span class='co'>## generate the data</span>
<span class='co'>## generate X</span>
<span class='no'>p</span> <span class='kw'>&lt;-</span> <span class='fl'>2</span>
<span class='no'>n</span> <span class='kw'>&lt;-</span> <span class='fl'>100</span>
<span class='no'>x</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/data.frame.html'>data.frame</a></span>(<span class='fu'><a href='https://rdrr.io/r/base/lapply.html'>replicate</a></span>(<span class='no'>p</span>, <span class='kw pkg'>stats</span><span class='kw ns'>::</span><span class='fu'><a href='https://rdrr.io/r/stats/Uniform.html'>runif</a></span>(<span class='no'>n</span>, -<span class='fl'>1</span>, <span class='fl'>1</span>)))

<span class='co'>## apply the function to the x's</span>
<span class='no'>f</span> <span class='kw'>&lt;-</span> <span class='kw'>function</span>(<span class='no'>x</span>) <span class='fl'>0.5</span> + <span class='fl'>0.3</span>*<span class='no'>x</span>[<span class='fl'>1</span>] + <span class='fl'>0.2</span>*<span class='no'>x</span>[<span class='fl'>2</span>]
<span class='no'>smooth</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/apply.html'>apply</a></span>(<span class='no'>x</span>, <span class='fl'>1</span>, <span class='kw'>function</span>(<span class='no'>z</span>) <span class='fu'>f</span>(<span class='no'>z</span>))

<span class='co'>## generate Y ~ Normal (smooth, 1)</span>
<span class='no'>y</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/matrix.html'>matrix</a></span>(<span class='fu'><a href='https://rdrr.io/r/stats/Binomial.html'>rbinom</a></span>(<span class='no'>n</span>, <span class='kw'>size</span> <span class='kw'>=</span> <span class='fl'>1</span>, <span class='kw'>prob</span> <span class='kw'>=</span> <span class='no'>smooth</span>))

<span class='co'>## set up a library for SuperLearner</span>
<span class='no'>learners</span> <span class='kw'>&lt;-</span> <span class='st'>"SL.ranger"</span>

<span class='co'>## using Y and X; use class-balanced folds</span>
<span class='no'>folds_1</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/sample.html'>sample</a></span>(<span class='fu'><a href='https://rdrr.io/r/base/rep.html'>rep</a></span>(<span class='fu'><a href='https://rdrr.io/r/base/seq.html'>seq_len</a></span>(<span class='fl'>2</span>), <span class='kw'>length</span> <span class='kw'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/sum.html'>sum</a></span>(<span class='no'>y</span> <span class='kw'>==</span> <span class='fl'>1</span>)))
<span class='no'>folds_0</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/sample.html'>sample</a></span>(<span class='fu'><a href='https://rdrr.io/r/base/rep.html'>rep</a></span>(<span class='fu'><a href='https://rdrr.io/r/base/seq.html'>seq_len</a></span>(<span class='fl'>2</span>), <span class='kw'>length</span> <span class='kw'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/sum.html'>sum</a></span>(<span class='no'>y</span> <span class='kw'>==</span> <span class='fl'>0</span>)))
<span class='no'>folds</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/vector.html'>vector</a></span>(<span class='st'>"numeric"</span>, <span class='fu'><a href='https://rdrr.io/r/base/length.html'>length</a></span>(<span class='no'>y</span>))
<span class='no'>folds</span>[<span class='no'>y</span> <span class='kw'>==</span> <span class='fl'>1</span>] <span class='kw'>&lt;-</span> <span class='no'>folds_1</span>
<span class='no'>folds</span>[<span class='no'>y</span> <span class='kw'>==</span> <span class='fl'>0</span>] <span class='kw'>&lt;-</span> <span class='no'>folds_0</span>
<span class='no'>est</span> <span class='kw'>&lt;-</span> <span class='fu'>vim</span>(<span class='no'>y</span>, <span class='no'>x</span>, <span class='kw'>indx</span> <span class='kw'>=</span> <span class='fl'>2</span>, <span class='kw'>type</span> <span class='kw'>=</span> <span class='st'>"r_squared"</span>,
           <span class='kw'>alpha</span> <span class='kw'>=</span> <span class='fl'>0.05</span>, <span class='kw'>run_regression</span> <span class='kw'>=</span> <span class='fl'>TRUE</span>,
           <span class='kw'>SL.library</span> <span class='kw'>=</span> <span class='no'>learners</span>, <span class='kw'>cvControl</span> <span class='kw'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span>(<span class='kw'>V</span> <span class='kw'>=</span> <span class='fl'>5</span>),
           <span class='kw'>folds</span> <span class='kw'>=</span> <span class='no'>folds</span>)</div><div class='output co'>#&gt; Error in data.frame(..., check.names = FALSE) : 
#&gt;   arguments imply differing number of rows: 41, 39</div><div class='output co'>#&gt; <span class='warning'>Warning: Error in algorithm SL.ranger </span>
#&gt; <span class='warning'>  The Algorithm will be removed from the Super Learner (i.e. given weight 0) </span></div><div class='output co'>#&gt; Error in data.frame(..., check.names = FALSE) : 
#&gt;   arguments imply differing number of rows: 41, 39</div><div class='output co'>#&gt; <span class='warning'>Warning: Error in algorithm SL.ranger </span>
#&gt; <span class='warning'>  The Algorithm will be removed from the Super Learner (i.e. given weight 0) </span></div><div class='output co'>#&gt; Error in data.frame(..., check.names = FALSE) : 
#&gt;   arguments imply differing number of rows: 41, 39</div><div class='output co'>#&gt; <span class='warning'>Warning: Error in algorithm SL.ranger </span>
#&gt; <span class='warning'>  The Algorithm will be removed from the Super Learner (i.e. given weight 0) </span></div><div class='output co'>#&gt; Error in data.frame(..., check.names = FALSE) : 
#&gt;   arguments imply differing number of rows: 41, 39</div><div class='output co'>#&gt; <span class='warning'>Warning: Error in algorithm SL.ranger </span>
#&gt; <span class='warning'>  The Algorithm will be removed from the Super Learner (i.e. given weight 0) </span></div><div class='output co'>#&gt; Error in data.frame(..., check.names = FALSE) : 
#&gt;   arguments imply differing number of rows: 42, 40</div><div class='output co'>#&gt; <span class='warning'>Warning: Error in algorithm SL.ranger </span>
#&gt; <span class='warning'>  The Algorithm will be removed from the Super Learner (i.e. given weight 0) </span></div><div class='output co'>#&gt; <span class='error'>Error in (function (Y, X, newX = NULL, family = gaussian(), SL.library,     method = "method.NNLS", id = NULL, verbose = FALSE, control = list(),     cvControl = list(), obsWeights = NULL, env = parent.frame()) {    time_start = proc.time()    if (is.character(method)) {        if (exists(method, mode = "list")) {            method &lt;- get(method, mode = "list")        }        else if (exists(method, mode = "function")) {            method &lt;- get(method, mode = "function")()        }    }    else if (is.function(method)) {        method &lt;- method()    }    if (!is.list(method)) {        stop("method is not in the appropriate format. Check out help('method.template')")    }    if (!is.null(method$require)) {        sapply(method$require, function(x) require(force(x),             character.only = TRUE))    }    control &lt;- do.call("SuperLearner.control", control)    cvControl &lt;- do.call("SuperLearner.CV.control", cvControl)    library &lt;- .createLibrary(SL.library)    .check.SL.library(library = c(unique(library$library$predAlgorithm),         library$screenAlgorithm))    call &lt;- match.call(expand.dots = TRUE)    if (!inherits(X, "data.frame"))         message("X is not a data frame. Check the algorithms in SL.library to make sure they are compatible with non data.frame inputs")    varNames &lt;- colnames(X)    N &lt;- dim(X)[1L]    p &lt;- dim(X)[2L]    k &lt;- nrow(library$library)    kScreen &lt;- length(library$screenAlgorithm)    Z &lt;- matrix(NA, N, k)    libraryNames &lt;- paste(library$library$predAlgorithm, library$screenAlgorithm[library$library$rowScreen],         sep = "_")    if (p &lt; 2 &amp; !identical(library$screenAlgorithm, "All")) {        warning("Screening algorithms specified in combination with single-column X.")    }    fitLibEnv &lt;- new.env()    assign("fitLibrary", vector("list", length = k), envir = fitLibEnv)    assign("libraryNames", libraryNames, envir = fitLibEnv)    evalq(names(fitLibrary) &lt;- libraryNames, envir = fitLibEnv)    errorsInCVLibrary &lt;- rep(0, k)    errorsInLibrary &lt;- rep(0, k)    if (is.null(newX)) {        newX &lt;- X    }    if (!identical(colnames(X), colnames(newX))) {        stop("The variable names and order in newX must be identical to the variable names and order in X")    }    if (sum(is.na(X)) &gt; 0 | sum(is.na(newX)) &gt; 0 | sum(is.na(Y)) &gt;         0) {        stop("missing data is currently not supported. Check Y, X, and newX for missing values")    }    if (!is.numeric(Y)) {        stop("the outcome Y must be a numeric vector")    }    if (is.character(family))         family &lt;- get(family, mode = "function", envir = parent.frame())    if (is.function(family))         family &lt;- family()    if (is.null(family$family)) {        print(family)        stop("'family' not recognized")    }    if (family$family != "binomial" &amp; isTRUE("cvAUC" %in% method$require)) {        stop("'method.AUC' is designed for the 'binomial' family only")    }    validRows &lt;- CVFolds(N = N, id = id, Y = Y, cvControl = cvControl)    if (is.null(id)) {        id &lt;- seq(N)    }    if (!identical(length(id), N)) {        stop("id vector must have the same dimension as Y")    }    if (is.null(obsWeights)) {        obsWeights &lt;- rep(1, N)    }    if (!identical(length(obsWeights), N)) {        stop("obsWeights vector must have the same dimension as Y")    }    .crossValFUN &lt;- function(valid, Y, dataX, id, obsWeights,         library, kScreen, k, p, libraryNames, saveCVFitLibrary) {        tempLearn &lt;- dataX[-valid, , drop = FALSE]        tempOutcome &lt;- Y[-valid]        tempValid &lt;- dataX[valid, , drop = FALSE]        tempWhichScreen &lt;- matrix(NA, nrow = kScreen, ncol = p)        tempId &lt;- id[-valid]        tempObsWeights &lt;- obsWeights[-valid]        for (s in seq(kScreen)) {            screen_fn = get(library$screenAlgorithm[s], envir = env)            testScreen &lt;- try(do.call(screen_fn, list(Y = tempOutcome,                 X = tempLearn, family = family, id = tempId,                 obsWeights = tempObsWeights)))            if (inherits(testScreen, "try-error")) {                warning(paste("replacing failed screening algorithm,",                   library$screenAlgorithm[s], ", with All()",                   "\n "))                tempWhichScreen[s, ] &lt;- TRUE            }            else {                tempWhichScreen[s, ] &lt;- testScreen            }            if (verbose) {                message(paste("Number of covariates in ", library$screenAlgorithm[s],                   " is: ", sum(tempWhichScreen[s, ]), sep = ""))            }        }        out &lt;- matrix(NA, nrow = nrow(tempValid), ncol = k)        if (saveCVFitLibrary) {            model_out &lt;- vector(mode = "list", length = k)        }        else {            model_out &lt;- NULL        }        for (s in seq(k)) {            pred_fn = get(library$library$predAlgorithm[s], envir = env)            testAlg &lt;- try(do.call(pred_fn, list(Y = tempOutcome,                 X = subset(tempLearn, select = tempWhichScreen[library$library$rowScreen[s],                   ], drop = FALSE), newX = subset(tempValid,                   select = tempWhichScreen[library$library$rowScreen[s],                     ], drop = FALSE), family = family, id = tempId,                 obsWeights = tempObsWeights)))            if (inherits(testAlg, "try-error")) {                warning(paste("Error in algorithm", library$library$predAlgorithm[s],                   "\n  The Algorithm will be removed from the Super Learner (i.e. given weight 0) \n"))            }            else {                out[, s] &lt;- testAlg$pred                if (saveCVFitLibrary) {                  model_out[[s]] &lt;- testAlg$fit                }            }            if (verbose)                 message(paste("CV", libraryNames[s]))        }        if (saveCVFitLibrary) {            names(model_out) &lt;- libraryNames        }        invisible(list(out = out, model_out = model_out))    }    time_train_start = proc.time()    crossValFUN_out &lt;- lapply(validRows, FUN = .crossValFUN,         Y = Y, dataX = X, id = id, obsWeights = obsWeights, library = library,         kScreen = kScreen, k = k, p = p, libraryNames = libraryNames,         saveCVFitLibrary = control$saveCVFitLibrary)    Z[unlist(validRows, use.names = FALSE), ] &lt;- do.call("rbind",         lapply(crossValFUN_out, "[[", "out"))    if (control$saveCVFitLibrary) {        cvFitLibrary &lt;- lapply(crossValFUN_out, "[[", "model_out")    }    else {        cvFitLibrary &lt;- NULL    }    errorsInCVLibrary &lt;- apply(Z, 2, function(x) anyNA(x))    if (sum(errorsInCVLibrary) &gt; 0) {        Z[, as.logical(errorsInCVLibrary)] &lt;- 0    }    if (all(Z == 0)) {        stop("All algorithms dropped from library")    }    getCoef &lt;- method$computeCoef(Z = Z, Y = Y, libraryNames = libraryNames,         obsWeights = obsWeights, control = control, verbose = verbose,         errorsInLibrary = errorsInCVLibrary)    coef &lt;- getCoef$coef    names(coef) &lt;- libraryNames    time_train = proc.time() - time_train_start    if (!("optimizer" %in% names(getCoef))) {        getCoef["optimizer"] &lt;- NA    }    m &lt;- dim(newX)[1L]    predY &lt;- matrix(NA, nrow = m, ncol = k)    .screenFun &lt;- function(fun, list) {        screen_fn = get(fun, envir = env)        testScreen &lt;- try(do.call(screen_fn, list))        if (inherits(testScreen, "try-error")) {            warning(paste("replacing failed screening algorithm,",                 fun, ", with All() in full data", "\n "))            out &lt;- rep(TRUE, ncol(list$X))        }        else {            out &lt;- testScreen        }        return(out)    }    time_predict_start = proc.time()    whichScreen &lt;- sapply(library$screenAlgorithm, FUN = .screenFun,         list = list(Y = Y, X = X, family = family, id = id, obsWeights = obsWeights),         simplify = FALSE)    whichScreen &lt;- do.call(rbind, whichScreen)    .predFun &lt;- function(index, lib, Y, dataX, newX, whichScreen,         family, id, obsWeights, verbose, control, libraryNames) {        pred_fn = get(lib$predAlgorithm[index], envir = env)        testAlg &lt;- try(do.call(pred_fn, list(Y = Y, X = subset(dataX,             select = whichScreen[lib$rowScreen[index], ], drop = FALSE),             newX = subset(newX, select = whichScreen[lib$rowScreen[index],                 ], drop = FALSE), family = family, id = id, obsWeights = obsWeights)))        if (inherits(testAlg, "try-error")) {            warning(paste("Error in algorithm", lib$predAlgorithm[index],                 " on full data", "\n  The Algorithm will be removed from the Super Learner (i.e. given weight 0) \n"))            out &lt;- rep.int(NA, times = nrow(newX))        }        else {            out &lt;- testAlg$pred            if (control$saveFitLibrary) {                eval(bquote(fitLibrary[[.(index)]] &lt;- .(testAlg$fit)),                   envir = fitLibEnv)            }        }        if (verbose) {            message(paste("full", libraryNames[index]))        }        invisible(out)    }    predY &lt;- do.call("cbind", lapply(seq(k), FUN = .predFun,         lib = library$library, Y = Y, dataX = X, newX = newX,         whichScreen = whichScreen, family = family, id = id,         obsWeights = obsWeights, verbose = verbose, control = control,         libraryNames = libraryNames))    errorsInLibrary &lt;- apply(predY, 2, function(algorithm) anyNA(algorithm))    if (sum(errorsInLibrary) &gt; 0) {        if (sum(coef[as.logical(errorsInLibrary)]) &gt; 0) {            warning(paste0("Re-running estimation of coefficients removing failed algorithm(s)\n",                 "Original coefficients are: \n", paste(coef,                   collapse = ", "), "\n"))            Z[, as.logical(errorsInLibrary)] &lt;- 0            if (all(Z == 0)) {                stop("All algorithms dropped from library")            }            getCoef &lt;- method$computeCoef(Z = Z, Y = Y, libraryNames = libraryNames,                 obsWeights = obsWeights, control = control, verbose = verbose,                 errorsInLibrary = errorsInLibrary)            coef &lt;- getCoef$coef            names(coef) &lt;- libraryNames        }        else {            warning("Coefficients already 0 for all failed algorithm(s)")        }    }    getPred &lt;- method$computePred(predY = predY, coef = coef,         control = control)    time_predict = proc.time() - time_predict_start    colnames(predY) &lt;- libraryNames    if (sum(errorsInCVLibrary) &gt; 0) {        getCoef$cvRisk[as.logical(errorsInCVLibrary)] &lt;- NA    }    time_end = proc.time()    times = list(everything = time_end - time_start, train = time_train,         predict = time_predict)    out &lt;- list(call = call, libraryNames = libraryNames, SL.library = library,         SL.predict = getPred, coef = coef, library.predict = predY,         Z = Z, cvRisk = getCoef$cvRisk, family = family, fitLibrary = get("fitLibrary",             envir = fitLibEnv), cvFitLibrary = cvFitLibrary,         varNames = varNames, validRows = validRows, method = method,         whichScreen = whichScreen, control = control, cvControl = cvControl,         errorsInCVLibrary = errorsInCVLibrary, errorsInLibrary = errorsInLibrary,         metaOptimizer = getCoef$optimizer, env = env, times = times)    class(out) &lt;- c("SuperLearner")    return(out)})(cvControl = list(V = 5), family = structure(list(family = "gaussian",     link = "identity", linkfun = function (mu)     mu, linkinv = function (eta)     eta, variance = function (mu)     rep.int(1, length(mu)), dev.resids = function (y, mu, wt)     wt * ((y - mu)^2), aic = function (y, n, mu, wt, dev)     {        nobs &lt;- length(y)        nobs * (log(dev/nobs * 2 * pi) + 1) + 2 - sum(log(wt))    }, mu.eta = function (eta)     rep.int(1, length(eta)), initialize = expression({        n &lt;- rep.int(1, nobs)        if (is.null(etastart) &amp;&amp; is.null(start) &amp;&amp; is.null(mustart) &amp;&amp;             ((family$link == "inverse" &amp;&amp; any(y == 0)) || (family$link ==                 "log" &amp;&amp; any(y &lt;= 0))))             stop("cannot find valid starting values: please specify some")        mustart &lt;- y    }), validmu = function (mu)     TRUE, valideta = function (eta)     TRUE), class = "family"), Y = structure(c(0.764433333333334, 0.902233333333333, 0.2149, 0.113633333333333, 0.163666666666667, 0.608433333333333, 0.738933333333333, 0.189566666666667, 0.484666666666667, 0.877033333333333, 0.809833333333334, 0.5056, 0.157066666666667, 0.643933333333333, 0.825166666666667, 0.321433333333333, 0.265766666666667, 0.853833333333334, 0.4472, 0.647233333333333, 0.8316, 0.1507, 0.887333333333334, 0.277733333333333, 0.657933333333333, 0.206333333333333, 0.320666666666667, 0.2041, 0.2769, 0.380166666666667, 0.4723, 0.8114, 0.6948, 0.737433333333333, 0.832133333333334, 0.852933333333334, 0.556266666666667, 0.311533333333333, 0.377633333333333, 0.889633333333333, 0.6432, 0.368566666666666, 0.0991, 0.167533333333333, 0.673466666666667, 0.0982333333333334, 0.9135, 0.1101, 0.258366666666667, 0.644733333333333, 0.809066666666667), .Dim = c(51L, 1L)), X = structure(list(X1 = c(-0.89936764491722, 0.642063539475203, 0.910011454951018, 0.262080955784768, -0.562725538387895, 0.777011377271265, 0.770595634821802, 0.431493969634175, 0.841576346196234, 0.775185872800648, 0.536101073026657, -0.62865411490202, -0.866032996214926, -0.283621788490564, 0.364980682730675, -0.871613871771842, 0.877045304048806, 0.244893914554268, 0.375060570891947, -0.391587009653449, -0.928596283309162, -0.0665344465523958, -0.760094040073454, 0.138311227317899, 0.43771810317412, 0.488246066030115, -0.999680822249502, -0.117976860608906, 0.531815499532968, 0.396002641879022, -0.789792776107788, 0.0848640943877399, -0.19813460111618, 0.550507746171206, -0.74155769823119, -0.151507525704801, 0.804833794012666, 0.971339809242636, 0.418852666858584, 0.415821702219546, 0.0786657864227891, -0.28625799715519, 0.924248291645199, -0.386249139904976, -0.16325153876096, -0.390195575077087, -0.193326390814036, 0.312064551748335, -0.0846606446430087)), row.names = c(1L, 2L, 3L, 4L, 8L, 11L, 14L, 15L, 18L, 20L, 21L, 22L, 24L, 27L, 28L, 29L, 36L, 37L, 39L, 41L, 43L, 44L, 47L, 48L, 50L, 52L, 55L, 56L, 58L, 60L, 61L, 63L, 71L, 74L, 75L, 77L, 78L, 80L, 81L, 84L, 85L, 87L, 88L, 89L, 91L, 92L, 95L, 98L, 100L), class = "data.frame"), SL.library = "SL.ranger"): All algorithms dropped from library</span></div><div class='input'>
<span class='co'>## using pre-computed fitted values</span>
<span class='no'>full</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/SuperLearner/man/SuperLearner.html'>SuperLearner</a></span>(<span class='kw'>Y</span> <span class='kw'>=</span> <span class='no'>y</span>[<span class='no'>folds</span> <span class='kw'>==</span> <span class='fl'>1</span>], <span class='kw'>X</span> <span class='kw'>=</span> <span class='no'>x</span>[<span class='no'>folds</span> <span class='kw'>==</span> <span class='fl'>1</span>, ],
<span class='kw'>SL.library</span> <span class='kw'>=</span> <span class='no'>learners</span>, <span class='kw'>cvControl</span> <span class='kw'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span>(<span class='kw'>V</span> <span class='kw'>=</span> <span class='fl'>5</span>))
<span class='no'>full.fit</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/predict.html'>predict</a></span>(<span class='no'>full</span>)$<span class='no'>pred</span>
<span class='no'>reduced</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/SuperLearner/man/SuperLearner.html'>SuperLearner</a></span>(<span class='kw'>Y</span> <span class='kw'>=</span> <span class='no'>y</span>[<span class='no'>folds</span> <span class='kw'>==</span> <span class='fl'>2</span>], <span class='kw'>X</span> <span class='kw'>=</span> <span class='no'>x</span>[<span class='no'>folds</span> <span class='kw'>==</span> <span class='fl'>2</span>, -<span class='fl'>2</span>, <span class='kw'>drop</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>],
<span class='kw'>SL.library</span> <span class='kw'>=</span> <span class='no'>learners</span>, <span class='kw'>cvControl</span> <span class='kw'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span>(<span class='kw'>V</span> <span class='kw'>=</span> <span class='fl'>5</span>))
<span class='no'>red.fit</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/predict.html'>predict</a></span>(<span class='no'>reduced</span>)$<span class='no'>pred</span>

<span class='no'>est</span> <span class='kw'>&lt;-</span> <span class='fu'>vim</span>(<span class='kw'>Y</span> <span class='kw'>=</span> <span class='no'>y</span>, <span class='kw'>f1</span> <span class='kw'>=</span> <span class='no'>full.fit</span>, <span class='kw'>f2</span> <span class='kw'>=</span> <span class='no'>red.fit</span>,
            <span class='kw'>indx</span> <span class='kw'>=</span> <span class='fl'>2</span>, <span class='kw'>run_regression</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>, <span class='kw'>alpha</span> <span class='kw'>=</span> <span class='fl'>0.05</span>, <span class='kw'>folds</span> <span class='kw'>=</span> <span class='no'>folds</span>,
            <span class='kw'>type</span> <span class='kw'>=</span> <span class='st'>"accuracy"</span>)</div></pre>
  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">
    <nav id="toc" data-toggle="toc" class="sticky-top">
      <h2 data-toc-skip>Contents</h2>
    </nav>
  </div>
</div>


      <footer>
      <div class="copyright">
  <p>Developed by Brian D. Williamson, Noah Simon, Marco Carone.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.5.1.</p>
</div>

      </footer>
   </div>

  


  </body>
</html>


